import os
from pathlib import Path
from typing import List
from pypdf import PdfReader

# Cho OCR náº¿u mÃ¡y há»— trá»£ (cháº¡y local)
ENABLE_OCR = True

if ENABLE_OCR:
    try:
        from pdf2image import convert_from_path
        import pytesseract
        pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"
        OCR_AVAILABLE = True
    except ImportError:
        OCR_AVAILABLE = False
else:
    OCR_AVAILABLE = False


def extract_text_from_pdf(file_path: str) -> str:
    try:
        reader = PdfReader(file_path)
        text = ""
        for page in reader.pages:
            text += page.extract_text() or ""
        if text.strip():
            return text
        elif OCR_AVAILABLE:
            print(f"ğŸ“¸ OCR Ä‘ang xá»­ lÃ½ file: {file_path}")
            return extract_text_with_ocr(file_path)
        else:
            return ""
    except Exception as e:
        print(f"[Lá»—i Ä‘á»c PDF]: {file_path} - {e}")
        return ""


def extract_text_with_ocr(file_path: str) -> str:
    text = ""
    try:
        images = convert_from_path(file_path)
        for img in images:
            text += pytesseract.image_to_string(img, lang='vie+eng')
        return text
    except Exception as e:
        print(f"[Lá»—i OCR]: {file_path} - {e}")
        return ""


def load_all_pdf_texts(data_folder: str = "data") -> List[str]:
    texts = []
    for pdf_file in Path(data_folder).rglob("*.pdf"):
        print(f"ğŸ“„ Äang xá»­ lÃ½: {pdf_file}")
        content = extract_text_from_pdf(str(pdf_file))
        if content.strip():
            texts.append(content)
            print(f"âœ… TrÃ­ch xuáº¥t thÃ nh cÃ´ng: {pdf_file}")
        else:
            print(f"âš ï¸ KhÃ´ng Ä‘á»c Ä‘Æ°á»£c ná»™i dung: {pdf_file}")
    return texts

# ============================
# ğŸ” Pháº§n táº¡o vectorstore á»Ÿ Ä‘Ã¢y
# ============================

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.docstore.document import Document


def create_vector_store():
    raw_texts = load_all_pdf_texts("data")

    if not raw_texts:
        print("ğŸš« KhÃ´ng tÃ¬m tháº¥y ná»™i dung nÃ o tá»« PDF.")
        return

    # TÃ¡ch vÄƒn báº£n thÃ nh Ä‘oáº¡n nhá»
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    documents = []
    for text in raw_texts:
        docs = text_splitter.split_text(text)
        documents.extend([Document(page_content=doc) for doc in docs])

    # Embedding
    embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

    # Táº¡o vectorstore
    print("ğŸ”§ Äang táº¡o vectorstore...")
    db = FAISS.from_documents(documents, embedding_model)

    # LÆ°u vectorstore
    os.makedirs("vectorstore", exist_ok=True)
    db.save_local("vectorstore")
    print("âœ… ÄÃ£ lÆ°u vectorstore vÃ o thÆ° má»¥c vectorstore/")
